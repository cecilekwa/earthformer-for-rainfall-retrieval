dataset:
  NUM_WORKERS: 4 # Useful for when training on a CPU (but not really viable for large datasets), indicates the number of workers
  BATCH_SIZE: 4 #This must be the same as the micro batch size and indicates the batch size used to load in the data
  img_height: 248 #Height of the image
  img_width: 184 #Width of the image
  in_len: 9 #Number of timestep in the input sequence
  out_len: 1 #Number of timesteps in the output sequence
  seq_len: 10 #Total sequence length used to calculate the performance indicateors when metrics mode is set to 1 
  plot_stride: 2 # Not used
  interval_real_time: 15 #Not used
  sample_mode: "sequent" 
  stride: 1 
  layout: "NTHWC"
  metrics_mode: "0" #Defines how the metrics are calculated. Is especially relevant when you output more than one timestep 1 calculated the metrics seperately for everytimestep
  metrics_list: ['csi', 'pod', 'sucr', 'bias'] #metrics calculated over the test dataset, note that this isn't working correctly. 
  threshold_list: [0.6, 1.7, 2.7, 5, 8.6, 15] # This will be logtransformed in the main script!
  scale_list: [3, 5, 7, 9, 11] # For FSS computation
layout:
  in_len: 9 #Number of timesteps in the input sequence used for plotting
  out_len: 1 #Number of outputs used for plotting
  layout: "NTHWC" #The way your data should be configured
optim:
  total_batch_size: 32 #The accumulated batch size (must be dividable by the micro batch size)/ Macro batch size, total batch size / micro batch size = how many batches are accumulated before updating the model parameters
  micro_batch_size: 4 #The batch size at which the data is loaded in onto the GPU
  seed: 0 #Setting the same seed of data sequence 
  method: "adamw" #ADAMW optimizer = the only implemented optimizer in this model so don't change 
  lr: 8.0e-5 #The maximum learning rate
  wd: 1.0e-4 #The weight decay 
  gradient_clip_val: 1.0 #Gradient clipping to prevent exploding gradients
  max_epochs: 120 #Max number of epochs the model is run
  # scheduler
  lr_scheduler_mode: "cosine" #Not used
  min_lr_ratio: 1.0e-4 # Not used in the code
  warmup_min_lr_ratio: 1.0e-6 #Not used in the code
  warmup_percentage: 0.22 #Percentage of the entire number of steps that is used for increasing the learning rate to the actual lr set in line 27
  # early stopping
  early_stop: true
  early_stop_mode: "min" 
  early_stop_patience: 20 #If validation loss is not improving over 20 epochs the model training is stopped
  save_top_k: 1 #Each epoch the best performing weights on the validation dataset are saved
logging:
  logging_prefix: "ef4inca" 
  monitor_lr: true #The learning rate is monitored during training
  monitor_device: false #
  track_grad_norm: -1 #Level the gradient norm is logged using Tensorboard. Not used during development of this model. 
  use_wandb: false 
  computeFSS: false # true #not used
trainer:
  check_val_every_n_epoch: 1 #Number of times the model outputs are checked on the validation dataset
  log_step_ratio: 0.001 
  precision: "16-mixed" 
vis:
  train_example_data_idx_list: [0, ] #Defines which sample is plotted during training of the model
  val_example_data_idx_list: [80, ] #Defines which sample is plotted during training of the model
  test_example_data_idx_list: [0, 6, 9, 12, 13, 14, 15, 19, 28, 31, 35, 39, 44, 49, 54, 74, 75, 76, 78, 80, 90, 95, 107, 129, 137, 150, 166, 167, 171, 173, 175, 182, 190, 200, 201, 205, 207, 208, 211, 215, 225, 227, 228, 232, 239, 242, 245, 247, 248, 252, 262, 267, 274, 275, 278, 282, 289, 290, 296, 301, 303, 307, 309, 316, 320, 321, 324, 331, 337, 343, 351, 352, 358, 362, 371, 379, 388, 394, 405, 420, 430, 432, 435, 438, 446, 449, 455, 460, 470, 478, 479, 481, 483, 485, 487, ]  #Defines which test samples are plotted when creating test output
  eval_example_only: false
  plot_stride: 2 #Not used
model:
  input_shape: [9, 248, 184, 11] #Defines the shape of your input files 
  target_shape: [1, 248, 184, 1] #Defines the shape of your output file
  base_units: 128 #Defines the size of the Key, Query and Value matrix. Should be alligned with the last channel dimension after downsampling (line 108)
  scale_alpha: 1.0 #Defines the XXX

  enc_depth: [1, 1] #The length of this list defines the number of hierarchical layers used for encoding. The numbers within this list define the number of cuboid attention blocks within one hierarchical layer. 
  dec_depth: [1, 1] #The length of this list defines the number of hierarchical layers used for decoding. The numbers within this list define the number of cuboid attention blocks within one hierarchical layer. 
  enc_use_inter_ffn: true #Use of feed forward network in the encoder
  dec_use_inter_ffn: true #Use of feed farward network in the decoder
  dec_hierarchical_pos_embed: true #decode the positional embedding

  downsample: 2 #Number of downsample layers. Must allign with the length of the list in line 108 t/m 110
  downsample_type: "patch_merge" #The used method to downsample (see read me file for more information)
  upsample_type: "upsample" #The used method to upsample the data (see read me file for more information)

  num_global_vectors: 32 #Defines the number of global vectors used to capture system wide dynamics
  use_dec_self_global: true 
  dec_self_update_global: true
  use_dec_cross_global: true 
  use_global_vector_ffn: true 
  use_global_self_attn: false 
  separate_global_qkv: false 
  global_dim_ratio: 1
#Defines the attention patterns used
  self_pattern: "axial" 
  cross_self_pattern: "axial"
  cross_pattern: "cross_1x1"
  dec_cross_last_n_frames: null

  attn_drop: 0.1 
  proj_drop: 0.1
  ffn_drop: 0.1
  num_heads: 32 #Number of attention heads within the model; The W_Q, W_K and W_V matrix have the shape: base unit x (base unit / num_heads) 

  ffn_activation: "gelu" #activation function used in the feed forward network
  gated_ffn: true 
  norm_layer: "layer_norm"
  padding_type: "zeros" #For patch and merge and conv layers padding is used zero mode is used, but interp and xx are also possible 
  pos_embed_type: "t+h+w" #How the positional embedding is encoded
  use_relative_pos: true
  self_attn_use_final_proj: true
  dec_use_first_self_attn: false

  z_init_method: "zeros"
  checkpoint_level: 0

  initial_downsample_type: "stack_conv"
  initial_downsample_activation: "leaky" 
  initial_downsample_stack_conv_num_layers: 2 #Number of convolutional downsample layers should allign with the length of the lists in line 108 tm 110
  initial_downsample_stack_conv_dim_list: [32, 128] #[32, 128] #The channel dimension that is increased every conv+downsample layer
  initial_downsample_stack_conv_downscale_list: [3, 2] #[3, 2] #The division factor the spatial dimension (height x width) is reduced; for example 3, reduces the height and width dimensions by a factor 3. Subsequently the second conv+downsample layer scales it down by a factor of two, so the spatial dimension is decreased by a factor of 6 by the entire conv+downsample layer.  
  initial_downsample_stack_conv_num_conv_list: [2, 2] #[2, 2] #The number of convolutional layers within each conv+downsample layer 

  attn_linear_init_mode: "0"
  ffn_linear_init_mode: "1"
  conv_init_mode: "0"
  down_up_linear_init_mode: "0"
  norm_init_mode: "0"
